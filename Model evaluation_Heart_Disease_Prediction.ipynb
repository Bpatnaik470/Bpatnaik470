{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 6237267,
          "sourceType": "datasetVersion",
          "datasetId": 3583338
        }
      ],
      "dockerImageVersionId": 30527,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Heart Disease Prediction",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bpatnaik470/Bpatnaik470/blob/main/Model%20evaluation_Heart_Disease_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import os\n",
        "import shutil\n",
        "import kagglehub\n",
        "arezaei81_heartcsv_path = kagglehub.dataset_download('arezaei81/heartcsv')\n",
        "\n",
        "# Get the actual CSV file path within the downloaded directory\n",
        "for filename in os.listdir(arezaei81_heartcsv_path):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        csv_file_path = os.path.join(arezaei81_heartcsv_path, filename)\n",
        "        break  # Stop searching after finding the first CSV file\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "id": "PbKauu317XVc",
        "outputId": "4d3501ee-d1c9-46c8-d97f-d7edfcfad8d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import boxcox\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T21:44:14.430081Z",
          "iopub.execute_input": "2024-10-10T21:44:14.430579Z",
          "iopub.status.idle": "2024-10-10T21:44:15.74816Z",
          "shell.execute_reply.started": "2024-10-10T21:44:14.430541Z",
          "shell.execute_reply": "2024-10-10T21:44:15.747087Z"
        },
        "trusted": true,
        "id": "5kMXdoKHZvkG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Build an automated process to test many modeling techniques and ML algorithms with\n",
        "# your data to see which one yields the best results\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "def evaluate_models(X, y):\n",
        "  \"\"\"\n",
        "  Evaluates multiple machine learning models using GridSearchCV.\n",
        "\n",
        "  Args:\n",
        "    X: The feature data (independent variables).\n",
        "    y: The target variable (dependent variable).\n",
        "  \"\"\"\n",
        "\n",
        "  models = {\n",
        "      'Logistic Regression': LogisticRegression(),\n",
        "      'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "      'Support Vector Machine': SVC(),\n",
        "      'Decision Tree': DecisionTreeClassifier(),\n",
        "      'Random Forest': RandomForestClassifier(),\n",
        "      'Naive Bayes': GaussianNB(),\n",
        "      'Gradient Boosting': GradientBoostingClassifier(),\n",
        "      'Linear Discriminant Analysis': LinearDiscriminantAnalysis(),\n",
        "  }\n",
        "\n",
        "  results = {}\n",
        "  for model_name, model in models.items():\n",
        "    print(f\"Evaluating {model_name}...\")\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    # Define parameter grid (example, adjust as needed)\n",
        "    param_grid = {}\n",
        "    if model_name == 'K-Nearest Neighbors':\n",
        "      param_grid = {'model__n_neighbors': [3, 5, 7, 9]}\n",
        "    elif model_name == 'Support Vector Machine':\n",
        "      param_grid = {'model__kernel': ['linear', 'rbf'], 'model__C': [0.1, 1, 10]}\n",
        "    elif model_name == 'Decision Tree':\n",
        "      param_grid = {'model__max_depth': [3, 5, 7]}\n",
        "    elif model_name == 'Random Forest':\n",
        "      param_grid = {'model__n_estimators': [100, 200], 'model__max_depth': [3, 5]}\n",
        "    elif model_name == 'Logistic Regression':\n",
        "      param_grid = {'model__C': [0.1, 1, 10]}\n",
        "    elif model_name == 'Gradient Boosting':\n",
        "      param_grid = {'model__n_estimators': [100, 200], 'model__learning_rate': [0.1, 0.05]}\n",
        "\n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=StratifiedKFold(n_splits=5), scoring='accuracy')\n",
        "    grid_search.fit(X, y)\n",
        "\n",
        "    results[model_name] = {\n",
        "        'best_score': grid_search.best_score_,\n",
        "        'best_params': grid_search.best_params_,\n",
        "        'best_estimator': grid_search.best_estimator_ # Store the best estimator\n",
        "    }\n",
        "\n",
        "  return results\n",
        "\n",
        "\n",
        "# Load your data (replace 'arezaei81_heartcsv_path' with your dataset path)\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Assuming 'target' is your target variable\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Evaluate models\n",
        "model_results = evaluate_models(X_train, y_train)\n",
        "\n",
        "# Display results\n",
        "for model_name, result in model_results.items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(f\"  Best Score: {result['best_score']:.4f}\")\n",
        "    print(f\"  Best Parameters: {result['best_params']}\")\n",
        "\n",
        "\n",
        "# Choose the best model based on the results and further refine it using the test set.\n",
        "# Assuming you want to select the Decision Tree as the best model\n",
        "best_dt = model_results['Decision Tree']['best_estimator'] # Assign best_dt\n",
        "\n",
        "# Evaluate the optimized model on the train"
      ],
      "metadata": {
        "id": "yijswgglB-aH",
        "outputId": "ca36855c-5f9f-41e0-d038-538d36d89dd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Logistic Regression...\n",
            "Evaluating K-Nearest Neighbors...\n",
            "Evaluating Support Vector Machine...\n",
            "Evaluating Decision Tree...\n",
            "Evaluating Random Forest...\n",
            "Evaluating Naive Bayes...\n",
            "Evaluating Gradient Boosting...\n",
            "Evaluating Linear Discriminant Analysis...\n",
            "\n",
            "Logistic Regression:\n",
            "  Best Score: 0.8180\n",
            "  Best Parameters: {'model__C': 1}\n",
            "\n",
            "K-Nearest Neighbors:\n",
            "  Best Score: 0.8141\n",
            "  Best Parameters: {'model__n_neighbors': 5}\n",
            "\n",
            "Support Vector Machine:\n",
            "  Best Score: 0.8184\n",
            "  Best Parameters: {'model__C': 1, 'model__kernel': 'rbf'}\n",
            "\n",
            "Decision Tree:\n",
            "  Best Score: 0.7561\n",
            "  Best Parameters: {'model__max_depth': 7}\n",
            "\n",
            "Random Forest:\n",
            "  Best Score: 0.8261\n",
            "  Best Parameters: {'model__max_depth': 3, 'model__n_estimators': 100}\n",
            "\n",
            "Naive Bayes:\n",
            "  Best Score: 0.7890\n",
            "  Best Parameters: {}\n",
            "\n",
            "Gradient Boosting:\n",
            "  Best Score: 0.8056\n",
            "  Best Parameters: {'model__learning_rate': 0.1, 'model__n_estimators': 100}\n",
            "\n",
            "Linear Discriminant Analysis:\n",
            "  Best Score: 0.7974\n",
            "  Best Parameters: {}\n"
          ]
        }
      ]
    }
  ]
}