{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPaAMLMrNhuYTA0u5I7u17h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bpatnaik470/Bpatnaik470/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKqIaba2dGzF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf03071a"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dca27bb7"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce09e130"
      },
      "source": [
        "### Visual Observations: Histograms for Numerical Data\n",
        "\n",
        "To understand the distribution of numerical features, I will generate histograms for 'age', 'income', and 'visits'. This will help in identifying skewness, outliers, and the overall spread of these variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "942456c9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set up the aesthetic for the plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Create histograms for selected numerical columns\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "sns.histplot(df['age'], kde=True, ax=axes[0], color='skyblue')\n",
        "axes[0].set_title('Distribution of Age')\n",
        "axes[0].set_xlabel('Age')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "\n",
        "sns.histplot(df['income'], kde=True, ax=axes[1], color='lightcoral')\n",
        "axes[1].set_title('Distribution of Income')\n",
        "axes[1].set_xlabel('Income')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "\n",
        "sns.histplot(df['visits'], kde=True, ax=axes[2], color='lightgreen')\n",
        "axes[2].set_title('Distribution of Visits')\n",
        "axes[2].set_xlabel('Visits')\n",
        "axes[2].set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2f917cc"
      },
      "source": [
        "### Visual Observations: Count Plots for Categorical Data\n",
        "\n",
        "To observe the frequency of different categories within categorical features, I will create count plots for 'health', 'gender', and 'region'. This helps in understanding the class balance and predominant categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e622c81"
      },
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "sns.countplot(x='health', data=df, ax=axes[0], palette='viridis', hue='health', legend=False)\n",
        "axes[0].set_title('Count of Health Status')\n",
        "axes[0].set_xlabel('Health Status')\n",
        "axes[0].set_ylabel('Count')\n",
        "\n",
        "sns.countplot(x='gender', data=df, ax=axes[1], palette='plasma', hue='gender', legend=False)\n",
        "axes[1].set_title('Count of Gender')\n",
        "axes[1].set_xlabel('Gender')\n",
        "axes[1].set_ylabel('Count')\n",
        "\n",
        "sns.countplot(x='region', data=df, ax=axes[2], palette='cividis', hue='region', legend=False)\n",
        "axes[2].set_title('Count of Region')\n",
        "axes[2].set_xlabel('Region')\n",
        "axes[2].set_ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9521e5e8"
      },
      "source": [
        "# Task\n",
        "Import data from the `/NSMES1988.csv` file, perform data cleaning including checking for missing values, handling duplicates, and converting data types, then export the cleaned data to `cleaned_NSMES1988.csv`, and finally, summarize the entire process and key findings from the cleaning step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07d3ef38"
      },
      "source": [
        "## Import Data\n",
        "\n",
        "### Subtask:\n",
        "Import the data from the `/NSMES1988.csv` file into a pandas DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bd6cd1c"
      },
      "source": [
        "**Reasoning**:\n",
        "To import the data from the CSV file into a pandas DataFrame, I need to first import the pandas library and then use its `read_csv` function. Displaying the head of the DataFrame will allow for initial data inspection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37c25a65"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/NSMES1988.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68c223bb"
      },
      "source": [
        "## Clean Data\n",
        "\n",
        "### Subtask:\n",
        "Perform initial data cleaning, including checking for missing values, handling duplicates, and converting data types if necessary. I'll provide a summary of the cleaning steps performed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b624f430"
      },
      "source": [
        "**Reasoning**:\n",
        "To begin the data cleaning process as per the instructions, I need to inspect the DataFrame's information, including data types and non-null values, using the `.info()` method. This will help identify columns with potential missing values or incorrect data types.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67454cca"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e286cf5"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the data cleaning instructions, I will first check for duplicate rows in the DataFrame, then remove them if any are found, and finally drop the 'Unnamed: 0' column, which appears to be a redundant index.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbf6320c"
      },
      "source": [
        "df.to_json('NSMES1988.json', orient='records', indent=4)\n",
        "print(\"Cleaned data exported to 'NSMES1988.json'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8efc65e6"
      },
      "source": [
        "# To view a portion of the JSON file, we can read the first few lines\n",
        "with open('NSMES1988.json', 'r') as f:\n",
        "    for _ in range(10):\n",
        "        print(f.readline(), end='')\n",
        "    print(\"...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f22ca77d"
      },
      "source": [
        "print(f\"Number of duplicate rows before dropping: {df.duplicated().sum()}\")\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(f\"Number of duplicate rows after dropping: {df.duplicated().sum()}\")\n",
        "\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "    print(\"Dropped 'Unnamed: 0' column.\")\n",
        "else:\n",
        "    print(\"'Unnamed: 0' column not found.\")\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d85f5f4"
      },
      "source": [
        "**Reasoning**:\n",
        "To identify inconsistencies or values that might require standardization in the categorical columns, I need to display the unique values for each of the specified columns: 'gender', 'married', 'employed', 'insurance', 'medicaid', 'health', 'chronic', 'adl', and 'region'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "755cb67b"
      },
      "source": [
        "categorical_columns = ['gender', 'married', 'employed', 'insurance', 'medicaid', 'health', 'chronic', 'adl', 'region']\n",
        "\n",
        "for col in categorical_columns:\n",
        "    if col in df.columns:\n",
        "        print(f\"Unique values for '{col}': {df[col].unique()}\")\n",
        "    else:\n",
        "        print(f\"Column '{col}' not found in DataFrame.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8965de97"
      },
      "source": [
        "### Summary of Initial Data Cleaning\n",
        "\n",
        "**Missing Values:**\n",
        "- The `df.info()` output indicated that all columns have 4406 non-null entries, matching the total number of rows. This means there are **no missing values** in the dataset.\n",
        "\n",
        "**Duplicate Rows:**\n",
        "- The check for duplicate rows confirmed that there were **no duplicate rows** in the DataFrame before or after attempting to drop them.\n",
        "\n",
        "**Redundant Columns:**\n",
        "- The 'Unnamed: 0' column, which appeared to be a redundant index, was successfully **dropped** from the DataFrame.\n",
        "\n",
        "**Data Types and Categorical Inconsistencies:**\n",
        "- Data types generally appear appropriate for each column (e.g., `int64` for visit counts, `float64` for age and income, `object` for categorical variables).\n",
        "- For the categorical columns ('gender', 'married', 'employed', 'insurance', 'medicaid', 'health', 'chronic', 'adl', 'region'), unique values were inspected. All values are consistent and do not show any obvious inconsistencies or require standardization at this stage. The 'chronic' column, despite being an `int64`, presents a range of integer values, which are valid within its context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2d2df31"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the initial data cleaning steps (checking for missing values, handling duplicates, and converting data types) are complete, as summarized in the previous markdown block, the next step is to export the cleaned DataFrame to a new CSV file named `cleaned_NSMES1988.csv`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b18cd13a"
      },
      "source": [
        "df.to_csv('cleaned_NSMES1988.csv', index=False)\n",
        "print(\"Cleaned data exported to 'cleaned_NSMES1988.csv'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b03e6f6c"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the data import, cleaning, and export process, including any key findings from the cleaning step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "338df6ee"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The dataset from `/NSMES1988.csv` was successfully imported into a pandas DataFrame.\n",
        "*   The dataset contains 4406 rows and no missing values across any columns.\n",
        "*   No duplicate rows were found in the dataset.\n",
        "*   A redundant index column named 'Unnamed: 0' was identified and successfully dropped from the DataFrame.\n",
        "*   Data types for all columns were found to be appropriate (e.g., `int64` for counts, `float64` for numerical data like age and income, and `object` for categorical variables).\n",
        "*   Unique values for key categorical columns ('gender', 'married', 'employed', 'insurance', 'medicaid', 'health', 'chronic', 'adl', 'region') were consistent and did not require further standardization.\n",
        "*   The cleaned DataFrame was successfully exported to `cleaned_NSMES1988.csv`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The dataset is remarkably clean, requiring minimal preprocessing before analysis, which is beneficial for immediate statistical modeling or descriptive analysis.\n",
        "*   Given the consistency of categorical values, the next step could involve encoding these variables (e.g., one-hot encoding or label encoding) if they are to be used in machine learning models that require numerical input.\n",
        "\n",
        "\n"
      ]
    }
  ]
}